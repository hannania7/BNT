- 리눅스 사용법 습득
: 윈도우와 리눅스간 파일 이동을 다시 해보면서 공책에 필기함
: 리눅스에서 쉘스크립트를 실행하여 python파일을 불러와 python파일을 실행시키는 것을 실습함
 
- Gitlab에 해군 파일설명 + DBeaver 테이블 속성 + 테이블 명세서 이 세가지로 DB테이블 익히기(이어서)
: Hslice.py모듈은 MOHID300M, YES3K의 함수를 입력받은 날짜, 시간에 대한 경로를 찾고 그 경로에 대한 변수들을 통해 시그마를 z로 바꿈 -> 입력받은 수심(meter)의 데이터를 파싱 -> 파싱한 데이터로 새로운 nc파일 생성 -> subprocess.run 함수로 리눅스에서 리그리딩 작업을 함 -> 리그리딩 작업한 파일로 nc파일, txt파일 생성 -> 리그리딩 작업한 파일과 리그리딩 작업전 파일을 삭제(앞 과정에서 nc파일과 txt파일만 살음) -> 파일이 정상적으로 생성됐는 지 확인, min, max, avg 값 리턴가능
: MakeFilePath.py모듈은 각각의 python파일에서 경로를 만들어주는 모듈이다.
: ObsMain.py모듈은 ColManual.py와 연결되어 있고 관측자료 별 디렉토리 경로 생성 -> 수집 날짜로 분까지 나타내는 관측시간 파싱 -> 이 관측시간으로 관측자료 파일 경로 생성 -> 이 파일경로가 있는 지 확인 후 파일 읽기 -> 읽은 데이터에 데이터가 있으면 DB에 관측소 별로 테이블에 insert나 update시킴
: ParsingData.py모듈은 property파일을 property형식에 맞게 데이터 파싱, HF-Radar(*.tuv) 데이터 파일을 데이터 형식에 맞게 파싱, csv파일을 데이터 형식에 맞게 파싱하고 이 때 csv파일에서 get_parsing_csv함수를 호출하는데, 이는 csv형식의 데이터를 list형태로 반환시키는 역할을 한다.
: PreMain.py모듈은 해군 통합해양정보체계 예측자료를 파싱하여 전처리하는 모듈로서, model경우에 따라 방식이 다른데, scp작업과 최대 인덱스를 찾아 +1해서 저장하는 것이 키워드이다.
그리고 scp작업은 수집된 파일이 있으면 log에 기존의 내용에서 새로운 내용을 추가하는 것을 의미한다.
 
- 질문할 것
: ObsMain.py의 모듈인 def main부분에서 만약 Hfobject라고 한다면, read_obs_data()함수만 사용하고 make_idx_arr같은 함수는 사용하지 않은 이유
: ColManual.py모듈의 진행방법을 gitlab 해군에 써져 있는 것의 "입력한 번호(mng_data_col_head - no 컬럼), 날짜, 시간에 대해 데이터 수동 수집 모듈 진행"의 뜻이 무엇인 지 물어보기
: ColManual.py모듈과 DBInsertModule.py모듈의 차이점 여쭤보기
: PreMain.py모듈에서 data_name = ‘MOHID300M’에서 24~72인덱스에 해당하는 파일 데이터만 파싱하는 이유